# Map Reduce Pattern for Big Data Processing

## üß© Descripci√≥n

**MapReduce** es un patr√≥n de procesamiento de datos que divide una tarea compleja en dos fases fundamentales: **Map** y **Reduce**. Est√° dise√±ado para manejar de forma eficiente grandes vol√∫menes de datos distribuidos a trav√©s de m√∫ltiples nodos de c√≥mputo.

- **Map**: Procesa los datos de entrada y los transforma en pares clave-valor.
- **Reduce**: Agrupa estos pares por clave y realiza operaciones de agregaci√≥n para producir el resultado final.

Es ampliamente utilizado en entornos de Big Data, como an√°lisis de logs, procesamiento de eventos hist√≥ricos, y generaci√≥n de reportes masivos.

![Map Reduce Pattern](../images/map_reduce.png)

---

## ‚úÖ ¬øQu√© problema soluciona?

### Problemas comunes:
- Procesamiento ineficiente de grandes cantidades de datos en una sola m√°quina.
- Limitaciones de escalabilidad y recursos en sistemas monol√≠ticos.
- Procesamiento lento y costoso de tareas complejas como agregaciones, conteos o an√°lisis de logs.

### ¬øC√≥mo lo soluciona?
- Divide y conquista: separa la tarea en subprocesos paralelos distribuidos (Map).
- Luego consolida los resultados parciales (Reduce).
- Esto permite escalar horizontalmente el procesamiento y aprovechar m√∫ltiples m√°quinas o nodos de c√≥mputo.

---

## üéØ Casos de uso

- Conteo de palabras o frases en millones de documentos.
- An√°lisis de logs de tr√°fico web.
- Generaci√≥n de reportes de ventas o m√©tricas hist√≥ricas.
- Procesamiento de datos de sensores IoT en lote.
- Indexaci√≥n de grandes vol√∫menes de texto (como motores de b√∫squeda).

---

## ‚òÅÔ∏è Ejemplo de implementaci√≥n en la nube

| Plataforma         | Servicios relevantes                  |
|-------------------|----------------------------------------|
| AWS               | Amazon EMR, AWS Lambda + S3, AWS Glue |
| Google Cloud      | Cloud Dataflow (Apache Beam)           |
| Azure             | Azure HDInsight, Azure Data Lake       |
| Open Source       | Apache Hadoop, Apache Spark            |

---

## üß± Arquitectura

### 1. Data Source (Input Split)
- El dataset se divide en fragmentos manejables.
- Ejemplo: 1 archivo de 1TB dividido en 1000 archivos de 1GB.

### 2. Map Phase
- Cada fragmento es procesado por una funci√≥n "Map".
- Se generan pares clave-valor intermedios.

### 3. Shuffle and Sort
- Se agrupan los valores por clave.
- Redistribuci√≥n de los pares clave-valor para consolidar.

### 4. Reduce Phase
- Para cada clave, se aplican funciones de agregaci√≥n como `sum()`, `count()`, `average()`, etc.

### 5. Data Sink (Output)
- El resultado final se almacena en S3, HDFS, Data Lake u otra base de datos.

---

## üìà Beneficios
- Permite procesar datos a gran escala (> TB) de forma distribuida.
- Tolerancia a fallos mediante reintentos en tareas individuales.
- Escalabilidad horizontal (m√°s nodos = m√°s velocidad).
- Compatible con arquitecturas batch y serverless.

---

## ‚ö†Ô∏è Desaf√≠os
- No es adecuado para procesamiento en tiempo real (batch-oriented).
- La fase de Shuffle and Sort puede ser costosa en red y E/S.
- Necesidad de infraestructura distribuida para implementaciones grandes.
- Requiere dise√±ar funciones de Map y Reduce cuidadosamente para evitar cuellos de botella.

--- 

[Men√∫ Principal](https://github.com/wilfredoha/cloud-architecture-patterns)